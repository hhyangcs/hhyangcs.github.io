---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a fifth-year Ph.D. student at the State Key Lab of CAD&CG, Zhejiang University, advised by <a href="https://scholar.google.com/citations?user=vzxDyJoAAAAJ">Prof. Deng Cai</a> and <a href="https://scholar.google.com/citations?user=QLLFowsAAAAJ">Prof. Xiaofei He</a>. During my internship at Shanghai AI Laboratory, I closely collaborated with <a href="https://scholar.google.com.hk/citations?user=kWADCMUAAAAJ">Dr. Tong He</a>, <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ">Prof. Yu Qiao</a>, and <a href="https://scholar.google.com/citations?user=pw_0Z_UAAAAJ">Prof. Wanli Ouyang</a>.

My research interests include 3D vision, robotics, and AIGC. I have conducted research on 3D scene understanding, multi-modal learning, representation learning, and video depth estimation.


<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Publications 

## Video Generation

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">Arxiv 2024</div>
      <img src='images/depth_any_video.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

  **Depth Any Video with Scalable Synthetic Data**
  
  **Honghui Yang**<sup style="font-size: 1em; vertical-align: -0.4em;">*</sup>, Di Huang<sup style="font-size: 1em; vertical-align: -0.4em;">*</sup>, Wei Yin, Chunhua Shen, Haifeng Liu, Xiaofei He, Binbin Lin<sup>‚Ä†</sup>, Wanli Ouyang, Tong He<sup>‚Ä†</sup>
  
  Arxiv, 2024 (Under Review)
  
  </div>
</div>

## Robotics

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">Arxiv 2024</div>
      <img src='images/spa.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

  **SPA: 3D Spatial-Awareness Enables Effective Embodied Representation**

  Haoyi Zhu, **Honghui Yang**, Yating Wang, Jiange Yang, Limin Wang, Tong He<sup>‚Ä†</sup>

  Arxiv, 2024 (Under Review)

  </div>
</div>

## Representation Learning

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">CVPR 2024</div>
      <img src='images/unipad.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

  **UniPAD: A Universal Pre-training Paradigm for Autonomous Driving**

  **Honghui Yang**, Sha Zhang, Di Huang, Xiaoyang Wu, Haoyi Zhu, Tong He<sup>‚Ä†</sup>, Shixiang Tang, Hengshuang Zhao, Qibo Qiu, Binbin Lin<sup>‚Ä†</sup>, Xiaofei He, Wanli Ouyang

  CVPR, 2024

  </div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">Arxiv 2023</div>
      <img src='images/ponderv2.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

  **PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm**

  Haoyi Zhu<sup style="font-size: 1em; vertical-align: -0.4em;">*</sup>, **Honghui Yang**<sup style="font-size: 1em; vertical-align: -0.4em;">*</sup>, Xiaoyang Wu<sup style="font-size: 1em; vertical-align: -0.4em;">*</sup>, Di Huang<sup style="font-size: 1em; vertical-align: -0.4em;">*</sup>, Sha Zhang, Xianglong He, Hengshuang Zhao, Chunhua Shen, Yu Qiao, Tong He<sup>‚Ä†</sup>, Wanli Ouyang

  Arxiv, 2023 (TPAMI Under Review)

  </div>
</div>


<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">CVPR 2024</div>
      <img src='images/ponder.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

  **Ponder: Point Cloud Pre-training via Neural Rendering**

  Di Huang, Sida Peng, Tong He<sup>‚Ä†</sup>, **Honghui Yang**, Xiaowei Zhou, Wanli Ouyang

  ICCV, 2023

  </div>
</div>

# üíª Internships
- *2022.06 - 2024.10*, Shanghai AI Laboratory, China.
- *2019.10 - 2022.06*, Fabu Inc., China.

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

<!-- # üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->


